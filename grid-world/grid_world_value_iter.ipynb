{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid World \n",
    "Based on State Space Search (actions here are considered deterministic) <br><br>\n",
    "In the code below, the grid world looks as follows:\n",
    "\n",
    "<img src=\"grid_world_value_iter.png\" alt=\"example grid world\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "win_state = (0, 3)\n",
    "lose_state = (1, 3)\n",
    "start_state = (2, 0)\n",
    "walls = [(1, 1),(0, 1)]\n",
    "deteminstic = True\n",
    "grid_rows = 3\n",
    "grid_cols = 4\n",
    "uni_actions = ['up', 'down', 'left', 'right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, state=start_state):\n",
    "        self.state = state\n",
    "        self.is_end = False\n",
    "        self.determine = deteminstic\n",
    "\n",
    "    def give_reward(self):\n",
    "        if self.state == win_state:\n",
    "            return 1\n",
    "        elif self.state == lose_state:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def is_end_fn(self):\n",
    "        if (self.state == win_state) or (self.state == lose_state):\n",
    "            self.is_end = True\n",
    "\n",
    "    def next_position(self, action):\n",
    "        next_state = self.state\n",
    "        if action == 'up':\n",
    "            next_state = (self.state[0]-1, self.state[1])\n",
    "        elif action == 'down':\n",
    "            next_state = (self.state[0]+1, self.state[1])\n",
    "        elif action == 'left':\n",
    "            next_state = (self.state[0], self.state[1]-1)\n",
    "        elif action == 'right':\n",
    "            next_state = (self.state[0], self.state[1]+1)\n",
    "        if next_state[0] >= 0 and next_state[0] < grid_rows and next_state[1] >= 0 and next_state[1] < grid_cols and next_state not in walls:\n",
    "            return next_state\n",
    "        else:\n",
    "            return self.state\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.actions = ['up', 'down', 'left', 'right']\n",
    "        self.exp_rate = 0.3\n",
    "        self.lr = 0.2\n",
    "        self.visited_states = []\n",
    "        self.State = State()\n",
    "        # Stores the state values for each state\n",
    "        self.state_values = {}\n",
    "        for i in range(grid_rows):\n",
    "            for j in range(grid_cols):\n",
    "                    self.state_values[(i, j)] = 0\n",
    "\n",
    "    def choose_action(self):\n",
    "        max_next_reward = 0\n",
    "        action = \"\"\n",
    "        if np.random.uniform(0, 1) <= self.exp_rate:\n",
    "            action = np.random.choice(self.actions)\n",
    "        else:\n",
    "            for act in self.actions:\n",
    "                next_reward = self.state_values[self.State.next_position(act)]\n",
    "                if next_reward >= max_next_reward:\n",
    "                    action = act\n",
    "                    max_next_reward = next_reward\n",
    "        return action\n",
    "    \n",
    "    def go_to_next_state(self, action):\n",
    "        new_state = self.State.next_position(action)\n",
    "        return State(state=new_state)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.State = State()\n",
    "        self.visited_states = []\n",
    "\n",
    "    def learn(self, reward):\n",
    "        reward = reward\n",
    "        for state in reversed(self.visited_states):\n",
    "            reward = self.state_values[state] + self.lr * (reward - self.state_values[state])\n",
    "            self.state_values[state] = round(reward, 3)\n",
    "\n",
    "    def play(self, rounds=10):\n",
    "        for _ in range(rounds):\n",
    "            while True:\n",
    "                self.visited_states.append(self.State.state)\n",
    "                self.State.is_end_fn()\n",
    "                if self.State.is_end:\n",
    "                    reward = self.State.give_reward()\n",
    "                    self.state_values[self.State.state] = reward\n",
    "                    self.learn(reward)\n",
    "                    self.reset()\n",
    "                    #self.show_values()\n",
    "                    break\n",
    "                action = self.choose_action()\n",
    "                self.State = self.go_to_next_state(action)\n",
    "            #print(\"End of the game \" + str(_ + 1) + \"\\n\")\n",
    "\n",
    "    def show_values(self):\n",
    "        for i in range(0, grid_rows):\n",
    "            print('----------------------------------')\n",
    "            out = '| '\n",
    "            for j in range(0, grid_cols):\n",
    "                out += str(self.state_values[(i, j)]).ljust(6) + ' | '\n",
    "            print(out)\n",
    "        print('----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| 0.624  | 0      | 0.998  | 1.0    | \n",
      "----------------------------------\n",
      "| 0.627  | 0      | 0.984  | -1.0   | \n",
      "----------------------------------\n",
      "| 0.786  | 0.837  | 0.894  | 0.586  | \n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "agent = Agent()\n",
    "agent.play(300)\n",
    "agent.show_values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
